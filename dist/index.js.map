{"version":3,"sources":["../src/actions/webSearch.ts","../src/services/webSearchService.ts","../src/types.ts","../src/templates/searchTemplate.ts","../src/templates/searchResponseTemplate.ts","../src/utils/searchUtils.ts","../src/examples/webSearchExamples.ts","../src/actions/webExtract.ts","../src/utils/extractUtils.ts","../src/templates/extractParamsTemplate.ts","../src/templates/extractResponseTemplate.ts","../src/examples/webExtractExamples.ts","../src/services/webExtractService.ts","../src/index.ts"],"sourcesContent":["import {\n    type Action,\n    type HandlerCallback,\n    type IAgentRuntime,\n    type Memory,\n    type State,\n    elizaLogger,\n    composeContext,\n    generateObject,\n    generateText,\n    ModelClass,\n} from \"@elizaos/core\";\nimport { WebSearchService } from \"../services/webSearchService\";\nimport { SearchParamsSchema, type SearchResult } from \"../types\";\nimport { searchTemplate } from \"../templates/searchTemplate\";\nimport { searchResponseTemplate } from \"../templates/searchResponseTemplate\";\nimport { MaxTokens, DEFAULT_MAX_WEB_SEARCH_TOKENS } from \"../utils/searchUtils\";\nimport { webSearchExamples } from \"../examples/webSearchExamples\";\n\nexport const webSearch: Action = {\n    name: \"WEB_SEARCH\",\n    similes: [\n        \"SEARCH_WEB\",\n        \"INTERNET_SEARCH\",\n        \"LOOKUP\",\n        \"QUERY_WEB\",\n        \"FIND_ONLINE\",\n        \"SEARCH_ENGINE\",\n        \"WEB_LOOKUP\",\n        \"ONLINE_SEARCH\",\n        \"FIND_INFORMATION\",\n    ],\n    suppressInitialMessage: true,\n    description: \"Perform a web search to find information related to the message.\",\n    validate: async (runtime: IAgentRuntime) => {\n        return !!runtime.getSetting(\"TAVILY_API_KEY\");\n    },\n    handler: async (\n        runtime: IAgentRuntime,\n        message: Memory,\n        state: State,\n        _options: any,\n        callback: HandlerCallback\n    ) => {\n        state = (await runtime.composeState(message)) as State;\n        const recentMessagesData = state.recentMessagesData || [];\n        \n        const lastAgentMessage = recentMessagesData[recentMessagesData.length - 1];\n        const searchMessage = lastAgentMessage?.content?.text;\n        \n        elizaLogger.warn(\"Using message for search:\", {\n            fromAgent: !!lastAgentMessage,\n            text: searchMessage\n        });\n\n        try {\n            const searchParamsContext = composeContext({\n                state: {\n                    ...state,\n                    message: searchMessage\n                },\n                template: searchTemplate\n            });\n\n            const { query, ...options } = (await generateObject({\n                runtime,\n                context: searchParamsContext,\n                modelClass: ModelClass.SMALL,\n                schema: SearchParamsSchema,\n            })).object as { query: string; [key: string]: any };\n\n            const webSearchService = new WebSearchService();\n            await webSearchService.initialize(runtime);\n\n            const searchResponse = await webSearchService.search(query, options);\n\n            if (searchResponse && searchResponse.results.length) {\n                const enhancedContext = composeContext({\n                    state: {\n                        ...state,\n                        message: searchMessage,\n                        searchResponse: JSON.stringify({\n                            query,\n                            answer: searchResponse.answer,\n                            results: searchResponse.results\n                        })\n                    },\n                    template: searchResponseTemplate\n                });\n\n                const enhancedResponse = await generateText({\n                    runtime,\n                    context: enhancedContext,\n                    modelClass: ModelClass.SMALL,\n                });\n                \n                callback({\n                    text: MaxTokens(enhancedResponse, DEFAULT_MAX_WEB_SEARCH_TOKENS),\n                });\n            }\n        } catch (error) {\n            elizaLogger.error(\"Web search error:\", error);\n        }\n    },\n    examples: webSearchExamples\n} as Action;","import {\n    Service,\n    type IAgentRuntime,\n    ServiceType,\n} from \"@elizaos/core\";\nimport { tavily } from \"@tavily/core\";\nimport type { \n    IWebSearchService, \n    SearchOptions, \n    SearchResponse,\n    TavilyClient\n} from \"../types\";\n\nexport class WebSearchService extends Service implements IWebSearchService {\n    public tavilyClient: TavilyClient\n\n    async initialize(_runtime: IAgentRuntime): Promise<void> {\n        const apiKey = _runtime.getSetting(\"TAVILY_API_KEY\") as string;\n        if (!apiKey) {\n            throw new Error(\"TAVILY_API_KEY is not set\");\n        }\n        this.tavilyClient = tavily({ apiKey });\n    }\n\n    getInstance(): IWebSearchService {\n        return WebSearchService.getInstance();\n    }\n\n    static get serviceType(): ServiceType {\n        return ServiceType.WEB_SEARCH;\n    }\n\n    async search(\n        query: string,\n        options?: SearchOptions,\n    ): Promise<SearchResponse> {\n        try {\n            const tavilyOptions = {\n                searchDepth: options?.searchDepth || \"basic\",\n                topic: options?.topic || \"general\",\n                days: options?.days || 3,\n                maxResults: options?.maxResults || 1,\n                includeImages: options?.includeImages || false,\n                includeImageDescriptions: options?.includeImageDescriptions || false,\n                includeAnswer: options?.includeAnswer ?? true,\n                includeRawContent: options?.includeRawContent || false,\n                includeDomains: options?.includeDomains,\n                excludeDomains: options?.excludeDomains,\n                maxTokens: options?.maxTokens\n            };\n            \n            const response = await this.tavilyClient.search(query, tavilyOptions);\n            \n            return response;\n        } catch (error) {\n            throw error;\n        }\n    }\n}\n","import type { Service } from \"@elizaos/core\";\nimport { tavily } from \"@tavily/core\";\nimport { z } from \"zod\";\n\nexport type TavilyClient = ReturnType<typeof tavily>;\n\n// Web Search Service\nexport interface IWebSearchService extends Service {\n    search(query: string, options?: SearchOptions): Promise<SearchResponse>;\n}\n\nexport type SearchResult = {\n    title: string;\n    url: string;\n    content?: string;\n    score?: number;\n    publishedDate?: string;\n};\n\nexport type SearchImage = {\n    url: string;\n    description?: string;\n};\n\nexport type SearchResponse = {\n    answer?: string;\n    query: string;\n    responseTime: number;\n    images: SearchImage[];\n    results: SearchResult[];\n};\n\n/**\n * Options for web search\n * Aligned with Tavily API options\n */\nexport interface SearchOptions {\n    /** The depth of the search (\"basic\" or \"advanced\") */\n    searchDepth?: \"basic\" | \"advanced\";\n\n    /** The category of the search */\n    topic?: \"general\" | \"news\" | \"finance\";\n\n    /** Number of days back from current date (for \"news\" topic). Default: 3 */\n    days?: number;\n\n    /** Maximum number of results (0-20). Default: 5 */\n    maxResults?: number;\n\n    /** Include images in the response */\n    includeImages?: boolean;\n\n    /** Include descriptions for images */\n    includeImageDescriptions?: boolean;\n\n    /** Include a generated answer */\n    includeAnswer?: boolean;\n\n    /** Include raw content in results */\n    includeRawContent?: boolean;\n\n    /** List of domains to include in search */\n    includeDomains?: string[];\n\n    /** List of domains to exclude from search */\n    excludeDomains?: string[];\n\n    /** Maximum tokens in the response */\n    maxTokens?: number;\n}\n\nexport const SearchParamsSchema = z.object({\n    query: z.string(),\n    topic: z.enum([\"general\", \"news\"]).optional(),\n    maxResults: z.number().min(1).max(10).optional(),\n    days: z.number().optional(),\n    includeImages: z.boolean().optional(),\n    includeImageDescriptions: z.boolean().optional(),\n    includeRawContent: z.boolean().optional(),\n    includeDomains: z.array(z.string()).optional(),\n    excludeDomains: z.array(z.string()).optional(),\n    searchDepth: z.enum([\"basic\", \"advanced\"]).optional(),\n    timeRange: z.enum([\"day\", \"week\", \"month\", \"year\", \"d\", \"w\", \"m\", \"y\"]).optional()\n});\n\n// Web Extract Service\nexport interface IWebExtractService extends Service {\n    extract(\n        urls: string[],\n        options?: ExtractOptions,\n    ): Promise<ExtractResponse>;\n}\n\n/**\n * Options for web extraction\n */\nexport interface ExtractOptions {\n    includeImages?: boolean; // Include images\n    extractDepth?: \"basic\" | \"advanced\";\n}\n\n/**\n * Successful result from extraction\n */\nexport type SuccessfulExtractResult = {\n    url: string;\n    raw_content: string;\n    images?: string[]; // Only available if includeImages is set to true\n};\n\n/**\n * Failed result from extraction\n */\nexport type FailedExtractResult = {\n    url: string;\n    error: string;\n};\n\n/**\n * Response from web extraction API\n */\nexport type ExtractResponse = {\n    results: SuccessfulExtractResult[];\n    failed_results: FailedExtractResult[];\n    response_time: number;\n};","/**\n * Template to extract search query and options from user message.\n */\nexport const searchTemplate = `\nAnalyze the following message and extract:\n1. The search query (convert it to a simple search query suitable for a search engine)\n2. Optional parameters if specified:\n   - searchDepth: \"basic\" or \"advanced\"\n   - topic: \"general\" or \"news\"\n   - maxResults: number between 1 and 20\n\nCRITICAL JSON FORMATTING RULES:\n1. Use ONLY ASCII characters\n2. Use ONLY double quotes (\") for strings\n3. Numbers must be actual numbers (not strings)\n4. All fields must be at the root level (no nesting)\n\nQUERY FORMATTING RULES:\n1. Remove any personal pronouns or pleasantries\n2. Make it concise and search-engine friendly\n3. Remove any special characters or formatting\n4. Keep important keywords and context\n\nExamples of query transformation:\n- \"Can you search for information about the iPhone please?\" -> \"iPhone latest information\"\n- \"Find me news about Korian group\" -> \"Korian group latest news\"\n\nExample of VALID JSON structure:\n\\`\\`\\`json\n{\n    \"query\": \"Korian group latest news\",\n    \"maxResults\": 4,\n    \"topic\": \"news\",\n    \"includeAnswer\": true\n}\n\\`\\`\\`\n\nDefault values (do not include if using these):\n* searchDepth: \"basic\"\n* topic: \"general\"\n* maxResults: 1\n* includeAnswer: true\n\nMessage to analyze: {{message}}\n\nExtract the search parameters from the message above. Respond ONLY with a valid JSON object, nothing else.`; ","/**\n * Template to translate and format search response\n */\nexport const searchResponseTemplate = `\nYou will receive a JSON string containing a search response with:\n- query: the search query used\n- answer: main search result summary\n- results: array of relevant sources with titles, URLs, and content\n- options: search parameters used\n\nTASK:\n1. Parse and analyze the content:\n   - Use the query to understand the search context\n   - Extract key information from the answer\n   - Review content from each result\n   - Consider relevance scores and dates\n   - Use search options to understand the scope\n\n2. Create a comprehensive response:\n   - Focus on answering the original query\n   - Start with the most relevant information\n   - Add important details from source content\n   - Ensure technical accuracy\n   - Remove any redundancy\n\n3. Format requirements:\n   - Write in the language of the user's message\n   - Keep technical terms unchanged (code, URLs, version numbers)\n   - Use clear, professional language\n   - No introductory phrases or meta-commentary\n   - Match the language level of the original query\n\nOUTPUT FORMAT:\n[Main content in user's message language, directly answering the query]\n\nSources :\n[Numbered list of translated titles with original URLs]\n\nExample of GOOD response:\nPython 3.12 introduces significant performance improvements, including a 20% reduction in execution time and better memory management.\n\nSources :\n1. [Python 3.12 Release Notes](https://docs.python.org/3.12/whatsnew)\n2. [Performance Improvements in Python 3.12](https://example.com/article)\n\nExample of BAD response:\nI will talk to you about Python...\nHere is what I found on the latest news...\n\nUser message: {{message}}\nSearch response: {{searchResponse}}\n\nCRITICAL: Start directly with the content in user's message language, NO introductions or meta-commentary allowed.`; ","import { encodingForModel, type TiktokenModel } from \"js-tiktoken\";\nimport type { SearchOptions } from \"../types\";\n\nexport const DEFAULT_MAX_WEB_SEARCH_TOKENS = 4000;\nexport const DEFAULT_MODEL_ENCODING = \"gpt-3.5-turbo\";\n\n/**\n * Calculate the total number of tokens in a string\n */\nexport function getTotalTokensFromString(\n    str: string,\n    encodingName: TiktokenModel = DEFAULT_MODEL_ENCODING\n) {\n    const encoding = encodingForModel(encodingName);\n    return encoding.encode(str).length;\n}\n\n/**\n * Limit a string to a maximum number of tokens\n */\nexport function MaxTokens(\n    data: string,\n    maxTokens: number = DEFAULT_MAX_WEB_SEARCH_TOKENS\n): string {\n    if (getTotalTokensFromString(data) >= maxTokens) {\n        return data.slice(0, maxTokens);\n    }\n    return data;\n}\n\n/**\n * Validate search parameters and ensure proper types\n */\nexport function isValidSearchParams(params: any): params is { query: string } & SearchOptions {\n    if (typeof params !== 'object' || params === null) {\n        return false;\n    }\n\n    // Validate query\n    if (typeof params.query !== 'string' || params.query.trim().length === 0) {\n        return false;\n    }\n\n    // Check maxResults\n    if ('maxResults' in params) {\n        const maxResults = Number(params.maxResults);\n        if (isNaN(maxResults) || maxResults < 0 || maxResults > 20) {\n            return false;\n        }\n        params.maxResults = maxResults;\n    }\n\n    // Check topic\n    if ('topic' in params && !['general', 'news'].includes(params.topic)) {\n        return false;\n    }\n\n    // Check searchDepth\n    if ('searchDepth' in params && !['basic', 'advanced'].includes(params.searchDepth)) {\n        return false;\n    }\n\n    // Ensure includeAnswer is always true\n    params.includeAnswer = true;\n\n    return true;\n} ","/**\n * Examples of web search usage for the agent\n * These examples help the agent understand how to use the web search action\n */\nexport const webSearchExamples = [\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"Find the latest news about SpaceX launches.\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the latest news about SpaceX launches:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"Can you find 3 details about the iPhone 16 release?\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the details I found about the iPhone 16 release:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"What is the schedule for the next FIFA World Cup?\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the schedule for the next FIFA World Cup:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: { text: \"Check the latest stock price of Tesla.\" },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the latest stock price of Tesla I found:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"Find 5 trending movies in the US.\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the current trending movies in the US:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"What is the latest score in the NBA finals?\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the latest score from the NBA finals:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: { text: \"When is the next Apple keynote event?\" },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the information about the next Apple keynote event:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n]; ","import { \n    type Action, \n    type IAgentRuntime, \n    type Memory, \n    type State, \n    type HandlerCallback,\n    elizaLogger,\n    composeContext,\n    generateObjectDeprecated,\n    generateText,\n    ModelClass\n} from \"@elizaos/core\";\nimport { validateUrls, normalizeExtractParams } from \"../utils/extractUtils\";\nimport { extractParamsTemplate } from \"../templates/extractParamsTemplate\";\nimport { extractResponseTemplate } from \"../templates/extractResponseTemplate\";\nimport { webExtractExamples } from \"../examples/webExtractExamples\";\nimport { WebExtractService } from \"../services/webExtractService\";\nimport type { SuccessfulExtractResult, FailedExtractResult } from \"../types\";\n\nexport const webExtract: Action = {\n    name: \"WEB_EXTRACT\",\n    similes: [\n        \"EXTRACT_FROM_WEB\",\n        \"EXTRACT_FROM_URL\",\n        \"EXTRACT_FROM_PAGE\",\n        \"EXTRACT_FROM_HTML\",\n        \"EXTRACT_FROM_WEB_PAGE\",\n        \"LOOKUP_URL\",\n        \"LOOKUP_WEB_PAGE\",\n        \"LOOKUP_WEB_URL\",\n        \"LOOKUP_WEB_PAGE_URL\",\n        \"WEB_EXTRACT_INFORMATION\",\n        \"WEB_EXTRACT_FROM_URL\",\n        \"WEB_EXTRACT_FROM_PAGE\",\n        \"URL_EXTRACT\",\n    ],\n    suppressInitialMessage: true,\n    description: \"Perform a web urls information extraction\",\n    validate: async (runtime: IAgentRuntime) => {\n        return !!runtime.getSetting(\"TAVILY_API_KEY\");\n    },\n    handler: async (\n        runtime: IAgentRuntime,\n        message: Memory,\n        state: State,\n        _options: any,\n        callback: HandlerCallback\n    ) => {\n        state = (await runtime.composeState(message)) as State;\n        let extractResponse;\n        let extractionResultsText = \"\";\n        let status = \"success\"; // Default status\n\n        try {\n            // Use the template to extract URLs and options\n            const extractParamsContext = composeContext({\n                state: {\n                    ...state,\n                    message: message.content.text\n                },\n                template: extractParamsTemplate\n            });\n\n            const extractParams = await generateObjectDeprecated({\n                runtime,\n                context: extractParamsContext,\n                modelClass: ModelClass.SMALL,\n            });\n            \n            // Normalize parameters using utility function\n            const normalizedParams = normalizeExtractParams(extractParams || {});\n            \n            // Validate URLs\n            const validUrls = validateUrls(normalizedParams.urls);\n\n            if (validUrls.length === 0) {\n                // No valid URLs found\n                extractionResultsText = \"No valid URLs were found in the message. Please provide valid URLs starting with http:// or https://.\\n\";\n                status = \"no_results\";\n            } else {\n                const webExtractService = new WebExtractService();\n                await webExtractService.initialize(runtime);\n                \n                const extractOptions = {\n                    includeImages: normalizedParams.includeImages !== undefined ? normalizedParams.includeImages : false,\n                    extractDepth: (normalizedParams.extractDepth as \"basic\" | \"advanced\") || \"basic\"\n                };\n\n                try {\n                    extractResponse = await webExtractService.extract(validUrls, extractOptions);\n                    \n                    if (extractResponse && extractResponse.results.length) {\n                        // Add successful results\n                        extractResponse.results.forEach((result: SuccessfulExtractResult, index: number) => {\n                            extractionResultsText += `URL ${index + 1}: ${result.url}\\n`;\n                            extractionResultsText += `Content: ${result.raw_content}\\n`;\n                            \n                            // Add images if available\n                            if (result.images && result.images.length > 0) {\n                                extractionResultsText += `Images: ${result.images.length} image(s) found\\n`;\n                            }\n                            \n                            extractionResultsText += \"\\n---\\n\\n\";\n                        });\n                        \n                        // Add failed results\n                        if (extractResponse.failed_results && extractResponse.failed_results.length > 0) {\n                            extractionResultsText += \"URLs not extracted:\\n\";\n                            \n                            extractResponse.failed_results.forEach((result: FailedExtractResult, index: number) => {\n                                extractionResultsText += `URL ${index + 1}: ${result.url} - Error: ${result.error}\\n`;\n                            });\n                            \n                            extractionResultsText += \"\\n---\\n\\n\";\n                        }\n                        \n                        status = \"success\";\n                    } else {\n                        extractionResultsText = \"Could not extract content from the provided URLs. Please check that the URLs are accessible and try again.\\n\";\n                        status = \"no_results\";\n                    }\n                } catch (error) {\n                    elizaLogger.error(\"Error in web extract handler:\", error);\n                    extractionResultsText = `An error occurred while extracting from URLs: ${error.message || \"Unknown error\"}\\n`;\n                    status = \"error\";\n                }\n            }\n        } catch (error) {\n            elizaLogger.error(\"Error in web extract handler:\", error);\n            extractionResultsText = `An error occurred while processing your request: ${error.message || \"Unknown error\"}`;\n            status = \"error\";\n        }\n        \n        // Use the template to format the response - single LLM call for all cases\n        const responseContext = composeContext({\n            state: {\n                ...state,\n                extractionResults: extractionResultsText,\n                responseTime: extractResponse ? extractResponse.response_time : 0,\n                status: status,\n                originalMessage: message.content.text\n            },\n            template: extractResponseTemplate\n        });\n        \n        const formattedResponse = await generateText({\n            runtime,\n            context: responseContext,\n            modelClass: ModelClass.MEDIUM,\n        });\n        \n        callback({\n            text: formattedResponse\n        });\n    },\n    examples: webExtractExamples\n} as Action;","import { encodingForModel, type TiktokenModel } from \"js-tiktoken\";\nimport type { ExtractOptions, SuccessfulExtractResult, FailedExtractResult, ExtractResponse } from \"../types\";\nimport { elizaLogger } from \"@elizaos/core\";\n\nexport const DEFAULT_MAX_EXTRACT_TOKENS = 8000;\nexport const DEFAULT_MODEL_ENCODING = \"gpt-3.5-turbo\";\n\n/**\n * Calculate the total number of tokens in a string\n */\nexport function getTotalTokensFromString(\n    str: string,\n    encodingName: TiktokenModel = DEFAULT_MODEL_ENCODING\n) {\n    const encoding = encodingForModel(encodingName);\n    return encoding.encode(str).length;\n}\n\n/**\n * Limit a string to a maximum number of tokens\n */\nexport function MaxTokens(\n    data: string,\n    maxTokens: number = DEFAULT_MAX_EXTRACT_TOKENS\n): string {\n    if (getTotalTokensFromString(data) >= maxTokens) {\n        return data.slice(0, maxTokens);\n    }\n    return data;\n}\n\n/**\n * Validate extracted URLs\n */\nexport function validateUrls(urls: string[]): string[] {\n    if (!urls || !Array.isArray(urls)) {\n        return [];\n    }\n\n    return urls.filter(url => {\n        try {\n            // Check if URL is valid\n            new URL(url);\n            return true;\n        } catch (e) {\n            return false;\n        }\n    });\n}\n\n/**\n * Validate extraction parameters\n */\nexport function isValidExtractParams(params: any): params is ExtractOptions {\n    if (typeof params !== 'object' || params === null) {\n        return false;\n    }\n    \n    // Check if the object has at least one of the expected properties\n    const hasExpectedProperties = 'includeImages' in params || 'extractDepth' in params || 'urls' in params;\n    if (!hasExpectedProperties) {\n        return false;\n    }\n    \n    // Check includeImages if present\n    if ('includeImages' in params) {\n        // Accept booleans and 'true'/'false' strings\n        if (typeof params.includeImages !== 'boolean') {\n            // If it's a string, accept 'true' or 'false'\n            if (typeof params.includeImages === 'string') {\n                const lowerValue = params.includeImages.toLowerCase();\n                if (lowerValue !== 'true' && lowerValue !== 'false') {\n                    return false;\n                }\n                // Accept the string, it will be converted later\n            } else {\n                return false;\n            }\n        }\n    }\n    \n    // Check extractDepth if present\n    if ('extractDepth' in params) {\n        if (typeof params.extractDepth !== 'string') {\n            return false;\n        }\n        \n        const validDepths = ['basic', 'advanced'];\n        if (!validDepths.includes(params.extractDepth.toLowerCase())) {\n            return false;\n        }\n    }\n    \n    // Check urls if present\n    if ('urls' in params) {\n        if (!Array.isArray(params.urls)) {\n            return false;\n        }\n        \n        // Check that all elements are strings\n        if (params.urls.some(url => typeof url !== 'string')) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n\n/**\n * Format extracted content to make it more readable\n */\nexport function formatExtractedContent(content: string): string {\n    if (!content) return '';\n    \n    // Remove excessive spaces and line breaks\n    let formatted = content.replace(/\\s+/g, ' ');\n    \n    // Limit content size\n    return MaxTokens(formatted);\n}\n\n/**\n * Create an empty extraction response\n */\nexport function createEmptyExtractResponse(): ExtractResponse {\n    return {\n        results: [],\n        failed_results: [],\n        response_time: 0\n    };\n}\n\n/**\n * Merge multiple extraction responses into one\n */\nexport function mergeExtractResponses(responses: ExtractResponse[]): ExtractResponse {\n    if (!responses || responses.length === 0) {\n        return createEmptyExtractResponse();\n    }\n    \n    const merged: ExtractResponse = {\n        results: [],\n        failed_results: [],\n        response_time: 0\n    };\n    \n    for (const response of responses) {\n        if (response.results) {\n            merged.results = [...merged.results, ...response.results];\n        }\n        \n        if (response.failed_results) {\n            merged.failed_results = [...merged.failed_results, ...response.failed_results];\n        }\n        \n        merged.response_time += response.response_time || 0;\n    }\n    \n    return merged;\n}\n\n/**\n * Normalize extraction parameters by fixing types and setting default values\n */\nexport function normalizeExtractParams(params: any): ExtractOptions & { urls: string[] } {\n    const normalizedParams: ExtractOptions & { urls: string[] } = {\n        urls: []\n    };\n    \n    // Fix includeImages if it's a string\n    if (typeof params.includeImages === 'string') {\n        const lowerValue = String(params.includeImages).toLowerCase();\n        normalizedParams.includeImages = lowerValue === 'true';\n    } else if (typeof params.includeImages === 'boolean') {\n        normalizedParams.includeImages = params.includeImages;\n    } else {\n        normalizedParams.includeImages = false; // Default value\n    }\n    \n    // Fix extractDepth if necessary\n    if (typeof params.extractDepth === 'string') {\n        const lowerValue = params.extractDepth.toLowerCase();\n        if (lowerValue === 'basic' || lowerValue === 'advanced') {\n            normalizedParams.extractDepth = lowerValue as \"basic\" | \"advanced\";\n        } else {\n            normalizedParams.extractDepth = \"basic\";\n        }\n    } else {\n        normalizedParams.extractDepth = \"basic\"; // Default value\n    }\n    \n    // Ensure urls is an array\n    if (Array.isArray(params.urls)) {\n        normalizedParams.urls = params.urls;\n    }\n    \n    return normalizedParams;\n} ","/**\n * Template to extract URLs and options for web extraction.\n * This template is used by the LLM to analyze the query and extract:\n * 1. The URLs to extract content from\n * 2. Whether to include images (default: false)\n * 3. The extraction depth (basic or advanced, default: basic)\n */\nexport const extractParamsTemplate = `\nAnalyze the following message and extract these parameters:\n1. The URLs to extract content from (up to 20 URLs)\n2. Whether to include images (default: false)\n3. The extraction depth (basic or advanced, default: basic)\n\nReturn a JSON object with these parameters. The JSON MUST be valid and properly formatted.\n\nExample response:\n\\`\\`\\`json\n{\n    \"urls\": [\n        \"https://en.wikipedia.org/wiki/Artificial_intelligence\",\n        \"https://en.wikipedia.org/wiki/Machine_learning\"\n    ],\n    \"includeImages\": true,\n    \"extractDepth\": \"advanced\"\n}\n\\`\\`\\`\n\nIMPORTANT FORMATTING RULES:\n- \"includeImages\" MUST be a boolean value (true or false without quotes), NOT a string\n- \"extractDepth\" MUST be a string (\"basic\" or \"advanced\" with quotes)\n- \"urls\" MUST be an array of strings, even if empty\n\nIf no image preference is specified, set \"includeImages\" to false (without quotes).\nIf no extraction depth is specified, set \"extractDepth\" to \"basic\" (with quotes).\n\nIMPORTANT CONTENT RULES:\n- Extract ALL URLs mentioned in the message\n- URLs must be valid and complete (starting with http:// or https://)\n- Maximum 20 URLs can be processed at once\n- Do not add URLs that weren't mentioned\n- If a URL is incomplete (e.g., \"wikipedia.org/wiki/Python\"), add the appropriate prefix (e.g., \"https://en.wikipedia.org/wiki/Python\")\n\nHere are some examples of how to interpret queries:\n- \"Extract content from https://en.wikipedia.org/wiki/Artificial_intelligence\" → {\"urls\": [\"https://en.wikipedia.org/wiki/Artificial_intelligence\"], \"includeImages\": false, \"extractDepth\": \"basic\"}\n- \"Get information from these pages: https://example.com and https://example.org with images\" → {\"urls\": [\"https://example.com\", \"https://example.org\"], \"includeImages\": true, \"extractDepth\": \"basic\"}\n- \"Extract detailed content from https://docs.python.org/3/\" → {\"urls\": [\"https://docs.python.org/3/\"], \"includeImages\": false, \"extractDepth\": \"advanced\"}\n\nMessage to analyze: {{message}}\n\nExtract the URLs and options from the message above. Respond ONLY with a valid JSON object, nothing else.\n`; ","/**\n * Template to format web content extraction response.\n * This template is used by the LLM to present extraction results\n * in a clear and readable way.\n */\nexport const extractResponseTemplate = `\nFormat web content extraction results in a clear and readable way.\n\nOriginal user message:\n{{message}}\n\nHere are the extraction results to format:\n{{extractionResults}}\n\nStatus: {{status}}\n\nFormatting rules:\n1. If status is \"error\" or \"no_results\", simply report the error message or explain why no results were found. Do not try to summarize non-existent content.\n2. If status is \"success\", then:\n   a. Present a concise summary of the content of each URL\n   b. Organize information in a structured and easy-to-read way\n   c. Highlight key points of the content\n   d. If images were found, mention it\n   e. If some URLs could not be extracted, explain why\n3. Use a professional and informative tone\n4. Respond in the same language as the original user message. If the original message is in French, respond in French. If it's in English, respond in English, etc.\n5. Format the response in a clean, modern way that works well in messaging platforms like Discord or Slack\n6. DO NOT include the status in your output\n7. Use markdown formatting to make the content more readable (bold for titles, bullet points for lists, etc.)\n\nRespond with the formatted content, without adding an introduction or conclusion.\n`; ","/**\n * Examples of web extraction usage for the agent\n * These examples help the agent understand how to extract information from specific web pages\n */\nexport const webExtractExamples = [\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"What are the main features of the latest iPhone? Here's the page: https://www.apple.com/iphone/\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the main features of the latest iPhone that I extracted from the page:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I'm interested in the Tesla Model 3 specs. Can you look at this page and tell me about them? https://www.tesla.com/model3/specs\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the technical specifications of the Tesla Model 3 that I extracted:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I want to make this lasagna recipe. What ingredients do I need and what are the steps? https://www.allrecipes.com/recipe/24074/alysias-basic-meat-lasagna/\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the ingredients and steps from the lasagna recipe that I extracted:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I need to understand the main points of this scientific article for my research. Can you help? https://www.nature.com/articles/s41586-020-2649-2\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the main conclusions from the scientific article that I extracted:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I'm looking for events to attend this weekend. Can you check these sites and tell me what's happening? https://www.eventbrite.com/ and https://www.meetup.com/\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here's the information about upcoming events that I extracted from both sites:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I want to buy a PlayStation 5 but I'm not sure where to get it. Can you compare the prices on these sites? https://www.amazon.com/PlayStation-5-Console-CFI-1215A01X/dp/B0BCNKKZ91 and https://www.bestbuy.com/site/sony-playstation-5-console/6523167.p\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here's a comparison of PlayStation 5 prices from the websites you provided:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"What's the weather going to be like in New York for the next few days? Check this link: https://weather.com/weather/tenday/l/New+York+NY\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here's the weather forecast for New York that I extracted:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I'm trying to decide which programming language to learn. Can you help me understand the differences between Python and Java by looking at their docs? https://docs.python.org/3/ and https://docs.oracle.com/en/java/\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the main differences between Python and Java based on their documentation:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n];\n","import {\n    Service,\n    type IAgentRuntime,\n    ServiceType,\n} from \"@elizaos/core\";\nimport { tavily } from \"@tavily/core\";\nimport type { \n    IWebExtractService, \n    ExtractOptions, \n    ExtractResponse,\n    SuccessfulExtractResult,\n    FailedExtractResult,\n    TavilyClient\n} from \"../types\";\n\nexport class WebExtractService extends Service implements IWebExtractService {\n    public tavilyClient: TavilyClient;\n\n    async initialize(_runtime: IAgentRuntime): Promise<void> {\n        const apiKey = _runtime.getSetting(\"TAVILY_API_KEY\") as string;\n        if (!apiKey) {\n            throw new Error(\"TAVILY_API_KEY is not set\");\n        }\n        this.tavilyClient = tavily({ apiKey });\n    }\n\n    getInstance(): IWebExtractService {\n        return WebExtractService.getInstance();\n    }\n\n    static get serviceType(): ServiceType {\n        return ServiceType.WEB_SEARCH;\n    }\n\n    async extract(\n        urls: string[],\n        options?: ExtractOptions,\n    ): Promise<ExtractResponse> {\n        try {\n            const tavilyOptions = {\n                includeImages: options?.includeImages || false,\n            };\n\n            const tavilyResponse = await this.tavilyClient.extract(urls);\n            \n            const anyResponse = tavilyResponse as any;\n            \n            const successfulResults: SuccessfulExtractResult[] = (anyResponse.results || []).map((result: any) => ({\n                url: result.url,\n                raw_content: result.rawContent || result.content || \"\",\n                images: result.images\n            }));\n            \n            const failedResults: FailedExtractResult[] = (anyResponse.failedResults || []).map((result: any) => ({\n                url: result.url,\n                error: result.error || \"Unknown error\"\n            }));\n            \n            const response: ExtractResponse = {\n                results: successfulResults,\n                failed_results: failedResults,\n                response_time: anyResponse.responseTime || 0\n            };\n            \n            return response;\n        } catch (error) {\n            throw error;\n        }\n    }\n}\n","import { webSearch } from \"./actions/webSearch\";\nimport { webExtract } from \"./actions/webExtract\";\n\nexport const webSearchPlugin = {\n    name: \"webSearch\",\n    description: \"Search the web and get news\",\n    actions: [webSearch, webExtract],\n};\n"],"mappings":";AAAA;AAAA,EAMI;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,OACG;;;ACXP;AAAA,EACI;AAAA,EAEA;AAAA,OACG;AACP,SAAS,cAAc;AAQhB,IAAM,mBAAN,MAAM,0BAAyB,QAAqC;AAAA,EAChE;AAAA,EAEP,MAAM,WAAW,UAAwC;AACrD,UAAM,SAAS,SAAS,WAAW,gBAAgB;AACnD,QAAI,CAAC,QAAQ;AACT,YAAM,IAAI,MAAM,2BAA2B;AAAA,IAC/C;AACA,SAAK,eAAe,OAAO,EAAE,OAAO,CAAC;AAAA,EACzC;AAAA,EAEA,cAAiC;AAC7B,WAAO,kBAAiB,YAAY;AAAA,EACxC;AAAA,EAEA,WAAW,cAA2B;AAClC,WAAO,YAAY;AAAA,EACvB;AAAA,EAEA,MAAM,OACF,OACA,SACuB;AACvB,QAAI;AACA,YAAM,gBAAgB;AAAA,QAClB,cAAa,mCAAS,gBAAe;AAAA,QACrC,QAAO,mCAAS,UAAS;AAAA,QACzB,OAAM,mCAAS,SAAQ;AAAA,QACvB,aAAY,mCAAS,eAAc;AAAA,QACnC,gBAAe,mCAAS,kBAAiB;AAAA,QACzC,2BAA0B,mCAAS,6BAA4B;AAAA,QAC/D,gBAAe,mCAAS,kBAAiB;AAAA,QACzC,oBAAmB,mCAAS,sBAAqB;AAAA,QACjD,gBAAgB,mCAAS;AAAA,QACzB,gBAAgB,mCAAS;AAAA,QACzB,WAAW,mCAAS;AAAA,MACxB;AAEA,YAAM,WAAW,MAAM,KAAK,aAAa,OAAO,OAAO,aAAa;AAEpE,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,YAAM;AAAA,IACV;AAAA,EACJ;AACJ;;;ACxDA,SAAS,SAAS;AAqEX,IAAM,qBAAqB,EAAE,OAAO;AAAA,EACvC,OAAO,EAAE,OAAO;AAAA,EAChB,OAAO,EAAE,KAAK,CAAC,WAAW,MAAM,CAAC,EAAE,SAAS;AAAA,EAC5C,YAAY,EAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,EAAE,EAAE,SAAS;AAAA,EAC/C,MAAM,EAAE,OAAO,EAAE,SAAS;AAAA,EAC1B,eAAe,EAAE,QAAQ,EAAE,SAAS;AAAA,EACpC,0BAA0B,EAAE,QAAQ,EAAE,SAAS;AAAA,EAC/C,mBAAmB,EAAE,QAAQ,EAAE,SAAS;AAAA,EACxC,gBAAgB,EAAE,MAAM,EAAE,OAAO,CAAC,EAAE,SAAS;AAAA,EAC7C,gBAAgB,EAAE,MAAM,EAAE,OAAO,CAAC,EAAE,SAAS;AAAA,EAC7C,aAAa,EAAE,KAAK,CAAC,SAAS,UAAU,CAAC,EAAE,SAAS;AAAA,EACpD,WAAW,EAAE,KAAK,CAAC,OAAO,QAAQ,SAAS,QAAQ,KAAK,KAAK,KAAK,GAAG,CAAC,EAAE,SAAS;AACrF,CAAC;;;AChFM,IAAM,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACAvB,IAAM,yBAAyB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACHtC,SAAS,wBAA4C;AAG9C,IAAM,gCAAgC;AACtC,IAAM,yBAAyB;AAK/B,SAAS,yBACZ,KACA,eAA8B,wBAChC;AACE,QAAM,WAAW,iBAAiB,YAAY;AAC9C,SAAO,SAAS,OAAO,GAAG,EAAE;AAChC;AAKO,SAAS,UACZ,MACA,YAAoB,+BACd;AACN,MAAI,yBAAyB,IAAI,KAAK,WAAW;AAC7C,WAAO,KAAK,MAAM,GAAG,SAAS;AAAA,EAClC;AACA,SAAO;AACX;;;ACxBO,IAAM,oBAAoB;AAAA,EAC7B;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS,EAAE,MAAM,yCAAyC;AAAA,IAC9D;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS,EAAE,MAAM,wCAAwC;AAAA,IAC7D;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AACJ;;;ANvFO,IAAM,YAAoB;AAAA,EAC7B,MAAM;AAAA,EACN,SAAS;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACJ;AAAA,EACA,wBAAwB;AAAA,EACxB,aAAa;AAAA,EACb,UAAU,OAAO,YAA2B;AACxC,WAAO,CAAC,CAAC,QAAQ,WAAW,gBAAgB;AAAA,EAChD;AAAA,EACA,SAAS,OACL,SACA,SACA,OACA,UACA,aACC;AA3CT;AA4CQ,YAAS,MAAM,QAAQ,aAAa,OAAO;AAC3C,UAAM,qBAAqB,MAAM,sBAAsB,CAAC;AAExD,UAAM,mBAAmB,mBAAmB,mBAAmB,SAAS,CAAC;AACzE,UAAM,iBAAgB,0DAAkB,YAAlB,mBAA2B;AAEjD,gBAAY,KAAK,6BAA6B;AAAA,MAC1C,WAAW,CAAC,CAAC;AAAA,MACb,MAAM;AAAA,IACV,CAAC;AAED,QAAI;AACA,YAAM,sBAAsB,eAAe;AAAA,QACvC,OAAO;AAAA,UACH,GAAG;AAAA,UACH,SAAS;AAAA,QACb;AAAA,QACA,UAAU;AAAA,MACd,CAAC;AAED,YAAM,EAAE,OAAO,GAAG,QAAQ,KAAK,MAAM,eAAe;AAAA,QAChD;AAAA,QACA,SAAS;AAAA,QACT,YAAY,WAAW;AAAA,QACvB,QAAQ;AAAA,MACZ,CAAC,GAAG;AAEJ,YAAM,mBAAmB,IAAI,iBAAiB;AAC9C,YAAM,iBAAiB,WAAW,OAAO;AAEzC,YAAM,iBAAiB,MAAM,iBAAiB,OAAO,OAAO,OAAO;AAEnE,UAAI,kBAAkB,eAAe,QAAQ,QAAQ;AACjD,cAAM,kBAAkB,eAAe;AAAA,UACnC,OAAO;AAAA,YACH,GAAG;AAAA,YACH,SAAS;AAAA,YACT,gBAAgB,KAAK,UAAU;AAAA,cAC3B;AAAA,cACA,QAAQ,eAAe;AAAA,cACvB,SAAS,eAAe;AAAA,YAC5B,CAAC;AAAA,UACL;AAAA,UACA,UAAU;AAAA,QACd,CAAC;AAED,cAAM,mBAAmB,MAAM,aAAa;AAAA,UACxC;AAAA,UACA,SAAS;AAAA,UACT,YAAY,WAAW;AAAA,QAC3B,CAAC;AAED,iBAAS;AAAA,UACL,MAAM,UAAU,kBAAkB,6BAA6B;AAAA,QACnE,CAAC;AAAA,MACL;AAAA,IACJ,SAAS,OAAO;AACZ,kBAAY,MAAM,qBAAqB,KAAK;AAAA,IAChD;AAAA,EACJ;AAAA,EACA,UAAU;AACd;;;AOzGA;AAAA,EAMI,eAAAA;AAAA,EACA,kBAAAC;AAAA,EACA;AAAA,EACA,gBAAAC;AAAA,EACA,cAAAC;AAAA,OACG;;;ACXP,SAAS,oBAAAC,yBAA4C;AAkC9C,SAAS,aAAa,MAA0B;AACnD,MAAI,CAAC,QAAQ,CAAC,MAAM,QAAQ,IAAI,GAAG;AAC/B,WAAO,CAAC;AAAA,EACZ;AAEA,SAAO,KAAK,OAAO,SAAO;AACtB,QAAI;AAEA,UAAI,IAAI,GAAG;AACX,aAAO;AAAA,IACX,SAAS,GAAG;AACR,aAAO;AAAA,IACX;AAAA,EACJ,CAAC;AACL;AAoHO,SAAS,uBAAuB,QAAkD;AACrF,QAAM,mBAAwD;AAAA,IAC1D,MAAM,CAAC;AAAA,EACX;AAGA,MAAI,OAAO,OAAO,kBAAkB,UAAU;AAC1C,UAAM,aAAa,OAAO,OAAO,aAAa,EAAE,YAAY;AAC5D,qBAAiB,gBAAgB,eAAe;AAAA,EACpD,WAAW,OAAO,OAAO,kBAAkB,WAAW;AAClD,qBAAiB,gBAAgB,OAAO;AAAA,EAC5C,OAAO;AACH,qBAAiB,gBAAgB;AAAA,EACrC;AAGA,MAAI,OAAO,OAAO,iBAAiB,UAAU;AACzC,UAAM,aAAa,OAAO,aAAa,YAAY;AACnD,QAAI,eAAe,WAAW,eAAe,YAAY;AACrD,uBAAiB,eAAe;AAAA,IACpC,OAAO;AACH,uBAAiB,eAAe;AAAA,IACpC;AAAA,EACJ,OAAO;AACH,qBAAiB,eAAe;AAAA,EACpC;AAGA,MAAI,MAAM,QAAQ,OAAO,IAAI,GAAG;AAC5B,qBAAiB,OAAO,OAAO;AAAA,EACnC;AAEA,SAAO;AACX;;;AC9LO,IAAM,wBAAwB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACF9B,IAAM,0BAA0B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACDhC,IAAM,qBAAqB;AAAA,EAC9B;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AACJ;;;AC7HA;AAAA,EACI,WAAAC;AAAA,EAEA,eAAAC;AAAA,OACG;AACP,SAAS,UAAAC,eAAc;AAUhB,IAAM,oBAAN,MAAM,2BAA0BF,SAAsC;AAAA,EAClE;AAAA,EAEP,MAAM,WAAW,UAAwC;AACrD,UAAM,SAAS,SAAS,WAAW,gBAAgB;AACnD,QAAI,CAAC,QAAQ;AACT,YAAM,IAAI,MAAM,2BAA2B;AAAA,IAC/C;AACA,SAAK,eAAeE,QAAO,EAAE,OAAO,CAAC;AAAA,EACzC;AAAA,EAEA,cAAkC;AAC9B,WAAO,mBAAkB,YAAY;AAAA,EACzC;AAAA,EAEA,WAAW,cAA2B;AAClC,WAAOD,aAAY;AAAA,EACvB;AAAA,EAEA,MAAM,QACF,MACA,SACwB;AACxB,QAAI;AACA,YAAM,gBAAgB;AAAA,QAClB,gBAAe,mCAAS,kBAAiB;AAAA,MAC7C;AAEA,YAAM,iBAAiB,MAAM,KAAK,aAAa,QAAQ,IAAI;AAE3D,YAAM,cAAc;AAEpB,YAAM,qBAAgD,YAAY,WAAW,CAAC,GAAG,IAAI,CAAC,YAAiB;AAAA,QACnG,KAAK,OAAO;AAAA,QACZ,aAAa,OAAO,cAAc,OAAO,WAAW;AAAA,QACpD,QAAQ,OAAO;AAAA,MACnB,EAAE;AAEF,YAAM,iBAAwC,YAAY,iBAAiB,CAAC,GAAG,IAAI,CAAC,YAAiB;AAAA,QACjG,KAAK,OAAO;AAAA,QACZ,OAAO,OAAO,SAAS;AAAA,MAC3B,EAAE;AAEF,YAAM,WAA4B;AAAA,QAC9B,SAAS;AAAA,QACT,gBAAgB;AAAA,QAChB,eAAe,YAAY,gBAAgB;AAAA,MAC/C;AAEA,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,YAAM;AAAA,IACV;AAAA,EACJ;AACJ;;;ALlDO,IAAM,aAAqB;AAAA,EAC9B,MAAM;AAAA,EACN,SAAS;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACJ;AAAA,EACA,wBAAwB;AAAA,EACxB,aAAa;AAAA,EACb,UAAU,OAAO,YAA2B;AACxC,WAAO,CAAC,CAAC,QAAQ,WAAW,gBAAgB;AAAA,EAChD;AAAA,EACA,SAAS,OACL,SACA,SACA,OACA,UACA,aACC;AACD,YAAS,MAAM,QAAQ,aAAa,OAAO;AAC3C,QAAI;AACJ,QAAI,wBAAwB;AAC5B,QAAI,SAAS;AAEb,QAAI;AAEA,YAAM,uBAAuBE,gBAAe;AAAA,QACxC,OAAO;AAAA,UACH,GAAG;AAAA,UACH,SAAS,QAAQ,QAAQ;AAAA,QAC7B;AAAA,QACA,UAAU;AAAA,MACd,CAAC;AAED,YAAM,gBAAgB,MAAM,yBAAyB;AAAA,QACjD;AAAA,QACA,SAAS;AAAA,QACT,YAAYC,YAAW;AAAA,MAC3B,CAAC;AAGD,YAAM,mBAAmB,uBAAuB,iBAAiB,CAAC,CAAC;AAGnE,YAAM,YAAY,aAAa,iBAAiB,IAAI;AAEpD,UAAI,UAAU,WAAW,GAAG;AAExB,gCAAwB;AACxB,iBAAS;AAAA,MACb,OAAO;AACH,cAAM,oBAAoB,IAAI,kBAAkB;AAChD,cAAM,kBAAkB,WAAW,OAAO;AAE1C,cAAM,iBAAiB;AAAA,UACnB,eAAe,iBAAiB,kBAAkB,SAAY,iBAAiB,gBAAgB;AAAA,UAC/F,cAAe,iBAAiB,gBAAyC;AAAA,QAC7E;AAEA,YAAI;AACA,4BAAkB,MAAM,kBAAkB,QAAQ,WAAW,cAAc;AAE3E,cAAI,mBAAmB,gBAAgB,QAAQ,QAAQ;AAEnD,4BAAgB,QAAQ,QAAQ,CAAC,QAAiC,UAAkB;AAChF,uCAAyB,OAAO,QAAQ,CAAC,KAAK,OAAO,GAAG;AAAA;AACxD,uCAAyB,YAAY,OAAO,WAAW;AAAA;AAGvD,kBAAI,OAAO,UAAU,OAAO,OAAO,SAAS,GAAG;AAC3C,yCAAyB,WAAW,OAAO,OAAO,MAAM;AAAA;AAAA,cAC5D;AAEA,uCAAyB;AAAA,YAC7B,CAAC;AAGD,gBAAI,gBAAgB,kBAAkB,gBAAgB,eAAe,SAAS,GAAG;AAC7E,uCAAyB;AAEzB,8BAAgB,eAAe,QAAQ,CAAC,QAA6B,UAAkB;AACnF,yCAAyB,OAAO,QAAQ,CAAC,KAAK,OAAO,GAAG,aAAa,OAAO,KAAK;AAAA;AAAA,cACrF,CAAC;AAED,uCAAyB;AAAA,YAC7B;AAEA,qBAAS;AAAA,UACb,OAAO;AACH,oCAAwB;AACxB,qBAAS;AAAA,UACb;AAAA,QACJ,SAAS,OAAO;AACZ,UAAAC,aAAY,MAAM,iCAAiC,KAAK;AACxD,kCAAwB,iDAAiD,MAAM,WAAW,eAAe;AAAA;AACzG,mBAAS;AAAA,QACb;AAAA,MACJ;AAAA,IACJ,SAAS,OAAO;AACZ,MAAAA,aAAY,MAAM,iCAAiC,KAAK;AACxD,8BAAwB,oDAAoD,MAAM,WAAW,eAAe;AAC5G,eAAS;AAAA,IACb;AAGA,UAAM,kBAAkBF,gBAAe;AAAA,MACnC,OAAO;AAAA,QACH,GAAG;AAAA,QACH,mBAAmB;AAAA,QACnB,cAAc,kBAAkB,gBAAgB,gBAAgB;AAAA,QAChE;AAAA,QACA,iBAAiB,QAAQ,QAAQ;AAAA,MACrC;AAAA,MACA,UAAU;AAAA,IACd,CAAC;AAED,UAAM,oBAAoB,MAAMG,cAAa;AAAA,MACzC;AAAA,MACA,SAAS;AAAA,MACT,YAAYF,YAAW;AAAA,IAC3B,CAAC;AAED,aAAS;AAAA,MACL,MAAM;AAAA,IACV,CAAC;AAAA,EACL;AAAA,EACA,UAAU;AACd;;;AMzJO,IAAM,kBAAkB;AAAA,EAC3B,MAAM;AAAA,EACN,aAAa;AAAA,EACb,SAAS,CAAC,WAAW,UAAU;AACnC;","names":["elizaLogger","composeContext","generateText","ModelClass","encodingForModel","Service","ServiceType","tavily","composeContext","ModelClass","elizaLogger","generateText"]}