{"version":3,"sources":["../src/actions/webSearch.ts","../src/services/webSearchService.ts","../src/templates/searchParamsTemplate.ts","../src/utils/searchUtils.ts","../src/examples/webSearchExamples.ts","../src/actions/webExtract.ts","../src/utils/extractUtils.ts","../src/templates/extractParamsTemplate.ts","../src/templates/extractResponseTemplate.ts","../src/examples/webExtractExamples.ts","../src/services/webExtractService.ts","../src/index.ts"],"sourcesContent":["import {\n    type Action,\n    type HandlerCallback,\n    type IAgentRuntime,\n    type Memory,\n    type State,\n    elizaLogger,\n    composeContext,\n    generateObjectDeprecated,\n    ModelClass,\n} from \"@elizaos/core\";\nimport { WebSearchService } from \"../services/webSearchService\";\nimport type { SearchResult } from \"../types\";\nimport { searchParamsTemplate } from \"../templates/searchParamsTemplate\";\nimport { \n    isValidSearchParams, \n    MaxTokens, \n    DEFAULT_MAX_WEB_SEARCH_TOKENS\n} from \"../utils/searchUtils\";\nimport { webSearchExamples } from \"../examples/webSearchExamples\";\n\nexport const webSearch: Action = {\n    name: \"WEB_SEARCH\",\n    similes: [\n        \"SEARCH_WEB\",\n        \"INTERNET_SEARCH\",\n        \"LOOKUP\",\n        \"QUERY_WEB\",\n        \"FIND_ONLINE\",\n        \"SEARCH_ENGINE\",\n        \"WEB_LOOKUP\",\n        \"ONLINE_SEARCH\",\n        \"FIND_INFORMATION\",\n    ],\n    suppressInitialMessage: true,\n    description: \"Perform a web search to find information related to the message.\",\n    validate: async (runtime: IAgentRuntime) => {\n        return !!runtime.getSetting(\"TAVILY_API_KEY\");\n    },\n    handler: async (\n        runtime: IAgentRuntime,\n        message: Memory,\n        state: State,\n        _options: any,\n        callback: HandlerCallback\n    ) => {\n        state = (await runtime.composeState(message)) as State;\n        const userId = runtime.agentId;\n        elizaLogger.log(\"Original search query:\", message.content.text);\n\n        try {\n            const recentMessagesData = state.recentMessagesData || [];\n            \n            // Find the index of the current user message in the conversation\n            const currentUserMessageIndex = recentMessagesData.findIndex(m => \n                m.content && m.content.text === message.content.text);\n            \n            // Find the agent message that comes AFTER this user message\n            // This is the agent's response to the current query\n            let lastRelevantAgentMessage = null;\n            if (currentUserMessageIndex >= 0 && currentUserMessageIndex < recentMessagesData.length - 1) {\n                // Look for the first agent message after the current user message\n                for (let i = currentUserMessageIndex + 1; i < recentMessagesData.length; i++) {\n                    const m = recentMessagesData[i];\n                    if (m.agentId === message.agentId) {\n                        lastRelevantAgentMessage = m;\n                        break;\n                    }\n                }\n            }\n            \n            // If we couldn't find a relevant message, fall back to the original approach\n            const lastAgentMessage = lastRelevantAgentMessage || recentMessagesData\n                .filter(m => m.agentId === message.agentId)\n                .pop();\n            \n            const lastAgentMessageText = lastAgentMessage?.content?.text || message.content.text;\n            \n            const searchParamsContext = composeContext({\n                state: {\n                    ...state,\n                    message: lastAgentMessageText\n                },\n                template: searchParamsTemplate\n            });\n\n            const searchParams = await generateObjectDeprecated({\n                runtime,\n                context: searchParamsContext,\n                modelClass: ModelClass.SMALL,\n            });\n\n            // Validate extracted parameters\n            const isParamsValid = isValidSearchParams(searchParams);\n            if (!isParamsValid) {\n                elizaLogger.warn(\"Invalid search parameters, using defaults\");\n            }\n\n            // Use the reformulated search query from the template\n            const webSearchPrompt = searchParams.query;\n            elizaLogger.log(\"Using reformulated search query:\", webSearchPrompt);\n\n            // The 'limit' parameter from searchParams is passed to the WebSearchService\n            // where it's used as the 'maxResults' parameter in the Tavily API call\n            const webSearchService = new WebSearchService();\n            await webSearchService.initialize(runtime);\n            \n            // Create search options with proper type conversion\n            const searchOptions = isParamsValid ? {\n                limit: typeof searchParams.limit === 'string' \n                    ? parseInt(searchParams.limit, 10) \n                    : searchParams.limit,\n                type: searchParams.type\n            } : undefined;\n            \n            const searchResponse = await webSearchService.search(\n                webSearchPrompt,\n                searchOptions\n            );\n\n            if (searchResponse && searchResponse.results.length) {\n                // Explicitly limit the number of results to display\n                const limit = searchOptions?.limit || 1;\n                \n                // Take only the first 'limit' results\n                const limitedResults = searchResponse.results.slice(0, limit);\n                \n                const responseList = searchResponse.answer\n                    ? `${searchResponse.answer}${\n                          Array.isArray(limitedResults) &&\n                          limitedResults.length > 0\n                              ? `\\n\\nFor more details, you can check out these resources:\\n${limitedResults\n                                    .map(\n                                        (result: SearchResult, index: number) =>\n                                            `${index + 1}. [${result.title}](${result.url})`\n                                    )\n                                    .join(\"\\n\")}`\n                              : \"\"\n                      }`\n                    : \"\";\n                \n                callback({\n                    text: MaxTokens(responseList, DEFAULT_MAX_WEB_SEARCH_TOKENS),\n                });\n            } else {\n                elizaLogger.error(\"Search failed or returned no data\");\n            }\n        } catch (error) {\n            elizaLogger.error(\"Error in web search handler:\", error);\n        }\n    },\n    examples: webSearchExamples,\n} as Action;","import {\n    Service,\n    type IAgentRuntime,\n    ServiceType,\n} from \"@elizaos/core\";\nimport { tavily } from \"@tavily/core\";\nimport type { \n    IWebSearchService, \n    SearchOptions, \n    SearchResponse,\n    TavilyClient\n} from \"../types\";\n\nexport class WebSearchService extends Service implements IWebSearchService {\n    public tavilyClient: TavilyClient\n\n    async initialize(_runtime: IAgentRuntime): Promise<void> {\n        const apiKey = _runtime.getSetting(\"TAVILY_API_KEY\") as string;\n        if (!apiKey) {\n            throw new Error(\"TAVILY_API_KEY is not set\");\n        }\n        this.tavilyClient = tavily({ apiKey });\n    }\n\n    getInstance(): IWebSearchService {\n        return WebSearchService.getInstance();\n    }\n\n    static get serviceType(): ServiceType {\n        return ServiceType.WEB_SEARCH;\n    }\n\n    async search(\n        query: string,\n        options?: SearchOptions,\n    ): Promise<SearchResponse> {\n        try {\n            let maxResults = 1;\n            \n            if (options && options.limit !== undefined) {\n                maxResults = typeof options.limit === 'string' \n                    ? parseInt(options.limit, 10) \n                    : options.limit;\n            }\n            \n            const tavilyOptions = {\n                includeAnswer: options?.includeAnswer ?? true,\n                maxResults: maxResults,\n                topic: options?.type || \"general\",\n                searchDepth: options?.searchDepth || \"basic\",\n                includeImages: options?.includeImages || false,\n                days: options?.days || 3,\n            };\n            \n            const response = await this.tavilyClient.search(query, tavilyOptions);\n            \n            return response;\n        } catch (error) {\n            throw error;\n        }\n    }\n}\n","/**\n * Template to extract search parameters from user query.\n * This template is used by the LLM to analyze the query and extract:\n * 1. The number of results desired (default: 1)\n * 2. The type of search (news or general, default: general)\n * 3. A reformulated search query for better results\n */\nexport const searchParamsTemplate = `\nAnalyze the following message and extract these parameters:\n1. The number of results desired (default: 1)\n2. The type of search (news or general, default: general)\n3. A reformulated search query that will yield the best search results\n\nReturn a JSON object with these parameters:\n\nExample response:\n\\`\\`\\`json\n{\n    \"limit\": 3,\n    \"type\": \"news\",\n    \"query\": \"SpaceX recent rocket launches and achievements\"\n}\n\\`\\`\\`\n\nIf no number of results is specified, set \"limit\" to 1.\nIf no type is specified, set \"type\" to \"general\".\nAlways include a reformulated \"query\" that is clear, specific, and optimized for search engines.\n\nIMPORTANT: Your reformulated query should:\n- Stay faithful to the original request\n- NOT add specific topics or technologies that weren't mentioned\n- NOT assume specific use cases unless clearly stated\n- Focus on the main subject of the query\n- Be concise and clear\n\nHere are some examples of how to interpret queries:\n- \"Find me 5 articles about AI\" → limit: 5, type: \"general\", query: \"artificial intelligence latest developments\"\n- \"What are the latest news about SpaceX?\" → limit: 1, type: \"news\", query: \"SpaceX recent news\"\n- \"Give me multiple sources about climate change\" → limit: 5, type: \"general\", query: \"climate change information\"\n- \"Find detailed information about quantum computing\" → limit: 3, type: \"general\", query: \"quantum computing overview\"\n- \"Show me recent developments in blockchain\" → limit: 3, type: \"news\", query: \"blockchain recent developments\"\n- \"Can you look up information about Cursor?\" → limit: 1, type: \"general\", query: \"Cursor software information\"\n\nMessage to analyze: {{message}}\n\nExtract the search parameters from the message above. Reformulate the query for better search results. Respond with a JSON markdown block.\n`; ","import { encodingForModel, type TiktokenModel } from \"js-tiktoken\";\nimport type { SearchOptions } from \"../types\";\n\nexport const DEFAULT_MAX_WEB_SEARCH_TOKENS = 4000;\nexport const DEFAULT_MODEL_ENCODING = \"gpt-3.5-turbo\";\n\n/**\n * Calculate the total number of tokens in a string\n */\nexport function getTotalTokensFromString(\n    str: string,\n    encodingName: TiktokenModel = DEFAULT_MODEL_ENCODING\n) {\n    const encoding = encodingForModel(encodingName);\n    return encoding.encode(str).length;\n}\n\n/**\n * Limit a string to a maximum number of tokens\n */\nexport function MaxTokens(\n    data: string,\n    maxTokens: number = DEFAULT_MAX_WEB_SEARCH_TOKENS\n): string {\n    if (getTotalTokensFromString(data) >= maxTokens) {\n        return data.slice(0, maxTokens);\n    }\n    return data;\n}\n\n/**\n * Validate extracted search parameters and convert strings to numbers if necessary\n */\nexport function isValidSearchParams(params: any): params is SearchOptions {\n    if (typeof params !== 'object' || params === null) {\n        return false;\n    }\n    \n    // Check limit\n    if ('limit' in params) {\n        // If limit is a string, try to convert it to a number\n        if (typeof params.limit === 'string') {\n            const parsedLimit = parseInt(params.limit, 10);\n            if (isNaN(parsedLimit) || parsedLimit < 1) {\n                return false;\n            }\n            // Automatically convert to number\n            params.limit = parsedLimit;\n        } else if (typeof params.limit !== 'number' || params.limit < 1 || !Number.isInteger(params.limit)) {\n            return false;\n        }\n    }\n    \n    // Check type\n    if ('type' in params) {\n        if (typeof params.type !== 'string' || (params.type !== 'news' && params.type !== 'general')) {\n            return false;\n        }\n    }\n    \n    return true;\n} ","/**\n * Examples of web search usage for the agent\n * These examples help the agent understand how to use the web search action\n */\nexport const webSearchExamples = [\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"Find the latest news about SpaceX launches.\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the latest news about SpaceX launches:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"Can you find 3 details about the iPhone 16 release?\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the details I found about the iPhone 16 release:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"What is the schedule for the next FIFA World Cup?\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the schedule for the next FIFA World Cup:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: { text: \"Check the latest stock price of Tesla.\" },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the latest stock price of Tesla I found:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"Find 5 trending movies in the US.\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the current trending movies in the US:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"What is the latest score in the NBA finals?\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the latest score from the NBA finals:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: { text: \"When is the next Apple keynote event?\" },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the information about the next Apple keynote event:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n]; ","import { \n    type Action, \n    type IAgentRuntime, \n    type Memory, \n    type State, \n    type HandlerCallback,\n    elizaLogger,\n    composeContext,\n    generateObjectDeprecated,\n    generateText,\n    ModelClass\n} from \"@elizaos/core\";\nimport { validateUrls, normalizeExtractParams } from \"../utils/extractUtils\";\nimport { extractParamsTemplate } from \"../templates/extractParamsTemplate\";\nimport { extractResponseTemplate } from \"../templates/extractResponseTemplate\";\nimport { webExtractExamples } from \"../examples/webExtractExamples\";\nimport { WebExtractService } from \"../services/webExtractService\";\nimport type { SuccessfulExtractResult, FailedExtractResult } from \"../types\";\n\nexport const webExtract: Action = {\n    name: \"WEB_EXTRACT\",\n    similes: [\n        \"EXTRACT_FROM_WEB\",\n        \"EXTRACT_FROM_URL\",\n        \"EXTRACT_FROM_PAGE\",\n        \"EXTRACT_FROM_HTML\",\n        \"EXTRACT_FROM_WEB_PAGE\",\n        \"LOOKUP_URL\",\n        \"LOOKUP_WEB_PAGE\",\n        \"LOOKUP_WEB_URL\",\n        \"LOOKUP_WEB_PAGE_URL\",\n        \"WEB_EXTRACT_INFORMATION\",\n        \"WEB_EXTRACT_FROM_URL\",\n        \"WEB_EXTRACT_FROM_PAGE\",\n        \"URL_EXTRACT\",\n    ],\n    suppressInitialMessage: true,\n    description: \"Perform a web urls information extraction\",\n    validate: async (runtime: IAgentRuntime) => {\n        return !!runtime.getSetting(\"TAVILY_API_KEY\");\n    },\n    handler: async (\n        runtime: IAgentRuntime,\n        message: Memory,\n        state: State,\n        _options: any,\n        callback: HandlerCallback\n    ) => {\n        state = (await runtime.composeState(message)) as State;\n        let extractResponse;\n        let extractionResultsText = \"\";\n        let status = \"success\"; // Default status\n\n        try {\n            // Use the template to extract URLs and options\n            const extractParamsContext = composeContext({\n                state: {\n                    ...state,\n                    message: message.content.text\n                },\n                template: extractParamsTemplate\n            });\n\n            const extractParams = await generateObjectDeprecated({\n                runtime,\n                context: extractParamsContext,\n                modelClass: ModelClass.SMALL,\n            });\n            \n            // Normalize parameters using utility function\n            const normalizedParams = normalizeExtractParams(extractParams || {});\n            \n            // Validate URLs\n            const validUrls = validateUrls(normalizedParams.urls);\n\n            if (validUrls.length === 0) {\n                // No valid URLs found\n                extractionResultsText = \"No valid URLs were found in the message. Please provide valid URLs starting with http:// or https://.\\n\";\n                status = \"no_results\";\n            } else {\n                const webExtractService = new WebExtractService();\n                await webExtractService.initialize(runtime);\n                \n                const extractOptions = {\n                    includeImages: normalizedParams.includeImages !== undefined ? normalizedParams.includeImages : false,\n                    extractDepth: (normalizedParams.extractDepth as \"basic\" | \"advanced\") || \"basic\"\n                };\n\n                try {\n                    extractResponse = await webExtractService.extract(validUrls, extractOptions);\n                    \n                    if (extractResponse && extractResponse.results.length) {\n                        // Add successful results\n                        extractResponse.results.forEach((result: SuccessfulExtractResult, index: number) => {\n                            extractionResultsText += `URL ${index + 1}: ${result.url}\\n`;\n                            extractionResultsText += `Content: ${result.raw_content}\\n`;\n                            \n                            // Add images if available\n                            if (result.images && result.images.length > 0) {\n                                extractionResultsText += `Images: ${result.images.length} image(s) found\\n`;\n                            }\n                            \n                            extractionResultsText += \"\\n---\\n\\n\";\n                        });\n                        \n                        // Add failed results\n                        if (extractResponse.failed_results && extractResponse.failed_results.length > 0) {\n                            extractionResultsText += \"URLs not extracted:\\n\";\n                            \n                            extractResponse.failed_results.forEach((result: FailedExtractResult, index: number) => {\n                                extractionResultsText += `URL ${index + 1}: ${result.url} - Error: ${result.error}\\n`;\n                            });\n                            \n                            extractionResultsText += \"\\n---\\n\\n\";\n                        }\n                        \n                        status = \"success\";\n                    } else {\n                        extractionResultsText = \"Could not extract content from the provided URLs. Please check that the URLs are accessible and try again.\\n\";\n                        status = \"no_results\";\n                    }\n                } catch (error) {\n                    elizaLogger.error(\"Error in web extract handler:\", error);\n                    extractionResultsText = `An error occurred while extracting from URLs: ${error.message || \"Unknown error\"}\\n`;\n                    status = \"error\";\n                }\n            }\n        } catch (error) {\n            elizaLogger.error(\"Error in web extract handler:\", error);\n            extractionResultsText = `An error occurred while processing your request: ${error.message || \"Unknown error\"}`;\n            status = \"error\";\n        }\n        \n        // Use the template to format the response - single LLM call for all cases\n        const responseContext = composeContext({\n            state: {\n                ...state,\n                extractionResults: extractionResultsText,\n                responseTime: extractResponse ? extractResponse.response_time : 0,\n                status: status,\n                originalMessage: message.content.text\n            },\n            template: extractResponseTemplate\n        });\n        \n        const formattedResponse = await generateText({\n            runtime,\n            context: responseContext,\n            modelClass: ModelClass.MEDIUM,\n        });\n        \n        callback({\n            text: formattedResponse\n        });\n    },\n    examples: webExtractExamples\n} as Action;","import { encodingForModel, type TiktokenModel } from \"js-tiktoken\";\nimport type { ExtractOptions, SuccessfulExtractResult, FailedExtractResult, ExtractResponse } from \"../types\";\nimport { elizaLogger } from \"@elizaos/core\";\n\nexport const DEFAULT_MAX_EXTRACT_TOKENS = 8000;\nexport const DEFAULT_MODEL_ENCODING = \"gpt-3.5-turbo\";\n\n/**\n * Calculate the total number of tokens in a string\n */\nexport function getTotalTokensFromString(\n    str: string,\n    encodingName: TiktokenModel = DEFAULT_MODEL_ENCODING\n) {\n    const encoding = encodingForModel(encodingName);\n    return encoding.encode(str).length;\n}\n\n/**\n * Limit a string to a maximum number of tokens\n */\nexport function MaxTokens(\n    data: string,\n    maxTokens: number = DEFAULT_MAX_EXTRACT_TOKENS\n): string {\n    if (getTotalTokensFromString(data) >= maxTokens) {\n        return data.slice(0, maxTokens);\n    }\n    return data;\n}\n\n/**\n * Validate extracted URLs\n */\nexport function validateUrls(urls: string[]): string[] {\n    if (!urls || !Array.isArray(urls)) {\n        return [];\n    }\n\n    return urls.filter(url => {\n        try {\n            // Check if URL is valid\n            new URL(url);\n            return true;\n        } catch (e) {\n            return false;\n        }\n    });\n}\n\n/**\n * Validate extraction parameters\n */\nexport function isValidExtractParams(params: any): params is ExtractOptions {\n    if (typeof params !== 'object' || params === null) {\n        return false;\n    }\n    \n    // Check if the object has at least one of the expected properties\n    const hasExpectedProperties = 'includeImages' in params || 'extractDepth' in params || 'urls' in params;\n    if (!hasExpectedProperties) {\n        return false;\n    }\n    \n    // Check includeImages if present\n    if ('includeImages' in params) {\n        // Accept booleans and 'true'/'false' strings\n        if (typeof params.includeImages !== 'boolean') {\n            // If it's a string, accept 'true' or 'false'\n            if (typeof params.includeImages === 'string') {\n                const lowerValue = params.includeImages.toLowerCase();\n                if (lowerValue !== 'true' && lowerValue !== 'false') {\n                    return false;\n                }\n                // Accept the string, it will be converted later\n            } else {\n                return false;\n            }\n        }\n    }\n    \n    // Check extractDepth if present\n    if ('extractDepth' in params) {\n        if (typeof params.extractDepth !== 'string') {\n            return false;\n        }\n        \n        const validDepths = ['basic', 'advanced'];\n        if (!validDepths.includes(params.extractDepth.toLowerCase())) {\n            return false;\n        }\n    }\n    \n    // Check urls if present\n    if ('urls' in params) {\n        if (!Array.isArray(params.urls)) {\n            return false;\n        }\n        \n        // Check that all elements are strings\n        if (params.urls.some(url => typeof url !== 'string')) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n\n/**\n * Format extracted content to make it more readable\n */\nexport function formatExtractedContent(content: string): string {\n    if (!content) return '';\n    \n    // Remove excessive spaces and line breaks\n    let formatted = content.replace(/\\s+/g, ' ');\n    \n    // Limit content size\n    return MaxTokens(formatted);\n}\n\n/**\n * Create an empty extraction response\n */\nexport function createEmptyExtractResponse(): ExtractResponse {\n    return {\n        results: [],\n        failed_results: [],\n        response_time: 0\n    };\n}\n\n/**\n * Merge multiple extraction responses into one\n */\nexport function mergeExtractResponses(responses: ExtractResponse[]): ExtractResponse {\n    if (!responses || responses.length === 0) {\n        return createEmptyExtractResponse();\n    }\n    \n    const merged: ExtractResponse = {\n        results: [],\n        failed_results: [],\n        response_time: 0\n    };\n    \n    for (const response of responses) {\n        if (response.results) {\n            merged.results = [...merged.results, ...response.results];\n        }\n        \n        if (response.failed_results) {\n            merged.failed_results = [...merged.failed_results, ...response.failed_results];\n        }\n        \n        merged.response_time += response.response_time || 0;\n    }\n    \n    return merged;\n}\n\n/**\n * Normalize extraction parameters by fixing types and setting default values\n */\nexport function normalizeExtractParams(params: any): ExtractOptions & { urls: string[] } {\n    const normalizedParams: ExtractOptions & { urls: string[] } = {\n        urls: []\n    };\n    \n    // Fix includeImages if it's a string\n    if (typeof params.includeImages === 'string') {\n        const lowerValue = String(params.includeImages).toLowerCase();\n        normalizedParams.includeImages = lowerValue === 'true';\n    } else if (typeof params.includeImages === 'boolean') {\n        normalizedParams.includeImages = params.includeImages;\n    } else {\n        normalizedParams.includeImages = false; // Default value\n    }\n    \n    // Fix extractDepth if necessary\n    if (typeof params.extractDepth === 'string') {\n        const lowerValue = params.extractDepth.toLowerCase();\n        if (lowerValue === 'basic' || lowerValue === 'advanced') {\n            normalizedParams.extractDepth = lowerValue as \"basic\" | \"advanced\";\n        } else {\n            normalizedParams.extractDepth = \"basic\";\n        }\n    } else {\n        normalizedParams.extractDepth = \"basic\"; // Default value\n    }\n    \n    // Ensure urls is an array\n    if (Array.isArray(params.urls)) {\n        normalizedParams.urls = params.urls;\n    }\n    \n    return normalizedParams;\n} ","/**\n * Template to extract URLs and options for web extraction.\n * This template is used by the LLM to analyze the query and extract:\n * 1. The URLs to extract content from\n * 2. Whether to include images (default: false)\n * 3. The extraction depth (basic or advanced, default: basic)\n */\nexport const extractParamsTemplate = `\nAnalyze the following message and extract these parameters:\n1. The URLs to extract content from (up to 20 URLs)\n2. Whether to include images (default: false)\n3. The extraction depth (basic or advanced, default: basic)\n\nReturn a JSON object with these parameters. The JSON MUST be valid and properly formatted.\n\nExample response:\n\\`\\`\\`json\n{\n    \"urls\": [\n        \"https://en.wikipedia.org/wiki/Artificial_intelligence\",\n        \"https://en.wikipedia.org/wiki/Machine_learning\"\n    ],\n    \"includeImages\": true,\n    \"extractDepth\": \"advanced\"\n}\n\\`\\`\\`\n\nIMPORTANT FORMATTING RULES:\n- \"includeImages\" MUST be a boolean value (true or false without quotes), NOT a string\n- \"extractDepth\" MUST be a string (\"basic\" or \"advanced\" with quotes)\n- \"urls\" MUST be an array of strings, even if empty\n\nIf no image preference is specified, set \"includeImages\" to false (without quotes).\nIf no extraction depth is specified, set \"extractDepth\" to \"basic\" (with quotes).\n\nIMPORTANT CONTENT RULES:\n- Extract ALL URLs mentioned in the message\n- URLs must be valid and complete (starting with http:// or https://)\n- Maximum 20 URLs can be processed at once\n- Do not add URLs that weren't mentioned\n- If a URL is incomplete (e.g., \"wikipedia.org/wiki/Python\"), add the appropriate prefix (e.g., \"https://en.wikipedia.org/wiki/Python\")\n\nHere are some examples of how to interpret queries:\n- \"Extract content from https://en.wikipedia.org/wiki/Artificial_intelligence\" → {\"urls\": [\"https://en.wikipedia.org/wiki/Artificial_intelligence\"], \"includeImages\": false, \"extractDepth\": \"basic\"}\n- \"Get information from these pages: https://example.com and https://example.org with images\" → {\"urls\": [\"https://example.com\", \"https://example.org\"], \"includeImages\": true, \"extractDepth\": \"basic\"}\n- \"Extract detailed content from https://docs.python.org/3/\" → {\"urls\": [\"https://docs.python.org/3/\"], \"includeImages\": false, \"extractDepth\": \"advanced\"}\n\nMessage to analyze: {{message}}\n\nExtract the URLs and options from the message above. Respond ONLY with a valid JSON object, nothing else.\n`; ","/**\n * Template to format web content extraction response.\n * This template is used by the LLM to present extraction results\n * in a clear and readable way.\n */\nexport const extractResponseTemplate = `\nFormat web content extraction results in a clear and readable way.\n\nOriginal user message:\n{{originalMessage}}\n\nHere are the extraction results to format:\n{{extractionResults}}\n\nStatus: {{status}}\n\nFormatting rules:\n1. If status is \"error\" or \"no_results\", simply report the error message or explain why no results were found. Do not try to summarize non-existent content.\n2. If status is \"success\", then:\n   a. Present a concise summary of the content of each URL\n   b. Organize information in a structured and easy-to-read way\n   c. Highlight key points of the content\n   d. If images were found, mention it\n   e. If some URLs could not be extracted, explain why\n3. Use a professional and informative tone\n4. Respond in the same language as the original user message. If the original message is in French, respond in French. If it's in English, respond in English, etc.\n5. Format the response in a clean, modern way that works well in messaging platforms like Discord or Slack\n6. DO NOT include the status in your output\n7. Use markdown formatting to make the content more readable (bold for titles, bullet points for lists, etc.)\n\nRespond with the formatted content, without adding an introduction or conclusion.\n`; ","/**\n * Examples of web extraction usage for the agent\n * These examples help the agent understand how to extract information from specific web pages\n */\nexport const webExtractExamples = [\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"What are the main features of the latest iPhone? Here's the page: https://www.apple.com/iphone/\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the main features of the latest iPhone that I extracted from the page:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I'm interested in the Tesla Model 3 specs. Can you look at this page and tell me about them? https://www.tesla.com/model3/specs\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the technical specifications of the Tesla Model 3 that I extracted:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I want to make this lasagna recipe. What ingredients do I need and what are the steps? https://www.allrecipes.com/recipe/24074/alysias-basic-meat-lasagna/\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the ingredients and steps from the lasagna recipe that I extracted:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I need to understand the main points of this scientific article for my research. Can you help? https://www.nature.com/articles/s41586-020-2649-2\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the main conclusions from the scientific article that I extracted:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I'm looking for events to attend this weekend. Can you check these sites and tell me what's happening? https://www.eventbrite.com/ and https://www.meetup.com/\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here's the information about upcoming events that I extracted from both sites:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I want to buy a PlayStation 5 but I'm not sure where to get it. Can you compare the prices on these sites? https://www.amazon.com/PlayStation-5-Console-CFI-1215A01X/dp/B0BCNKKZ91 and https://www.bestbuy.com/site/sony-playstation-5-console/6523167.p\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here's a comparison of PlayStation 5 prices from the websites you provided:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"What's the weather going to be like in New York for the next few days? Check this link: https://weather.com/weather/tenday/l/New+York+NY\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here's the weather forecast for New York that I extracted:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I'm trying to decide which programming language to learn. Can you help me understand the differences between Python and Java by looking at their docs? https://docs.python.org/3/ and https://docs.oracle.com/en/java/\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the main differences between Python and Java based on their documentation:\",\n                action: \"WEB_EXTRACT\",\n            },\n        },\n    ],\n];\n","import {\n    Service,\n    type IAgentRuntime,\n    ServiceType,\n} from \"@elizaos/core\";\nimport { tavily } from \"@tavily/core\";\nimport type { \n    IWebExtractService, \n    ExtractOptions, \n    ExtractResponse,\n    SuccessfulExtractResult,\n    FailedExtractResult,\n    TavilyClient\n} from \"../types\";\n\nexport class WebExtractService extends Service implements IWebExtractService {\n    public tavilyClient: TavilyClient;\n\n    async initialize(_runtime: IAgentRuntime): Promise<void> {\n        const apiKey = _runtime.getSetting(\"TAVILY_API_KEY\") as string;\n        if (!apiKey) {\n            throw new Error(\"TAVILY_API_KEY is not set\");\n        }\n        this.tavilyClient = tavily({ apiKey });\n    }\n\n    getInstance(): IWebExtractService {\n        return WebExtractService.getInstance();\n    }\n\n    static get serviceType(): ServiceType {\n        return ServiceType.WEB_SEARCH;\n    }\n\n    async extract(\n        urls: string[],\n        options?: ExtractOptions,\n    ): Promise<ExtractResponse> {\n        try {\n            const tavilyOptions = {\n                includeImages: options?.includeImages || false,\n            };\n\n            const tavilyResponse = await this.tavilyClient.extract(urls);\n            \n            const anyResponse = tavilyResponse as any;\n            \n            const successfulResults: SuccessfulExtractResult[] = (anyResponse.results || []).map((result: any) => ({\n                url: result.url,\n                raw_content: result.rawContent || result.content || \"\",\n                images: result.images\n            }));\n            \n            const failedResults: FailedExtractResult[] = (anyResponse.failedResults || []).map((result: any) => ({\n                url: result.url,\n                error: result.error || \"Unknown error\"\n            }));\n            \n            const response: ExtractResponse = {\n                results: successfulResults,\n                failed_results: failedResults,\n                response_time: anyResponse.responseTime || 0\n            };\n            \n            return response;\n        } catch (error) {\n            throw error;\n        }\n    }\n}\n","import { webSearch } from \"./actions/webSearch\";\nimport { webExtract } from \"./actions/webExtract\";\n\nexport const webSearchPlugin = {\n    name: \"webSearch\",\n    description: \"Search the web and get news\",\n    actions: [webSearch, webExtract],\n};\n"],"mappings":";AAAA;AAAA,EAMI;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,OACG;;;ACVP;AAAA,EACI;AAAA,EAEA;AAAA,OACG;AACP,SAAS,cAAc;AAQhB,IAAM,mBAAN,MAAM,0BAAyB,QAAqC;AAAA,EAChE;AAAA,EAEP,MAAM,WAAW,UAAwC;AACrD,UAAM,SAAS,SAAS,WAAW,gBAAgB;AACnD,QAAI,CAAC,QAAQ;AACT,YAAM,IAAI,MAAM,2BAA2B;AAAA,IAC/C;AACA,SAAK,eAAe,OAAO,EAAE,OAAO,CAAC;AAAA,EACzC;AAAA,EAEA,cAAiC;AAC7B,WAAO,kBAAiB,YAAY;AAAA,EACxC;AAAA,EAEA,WAAW,cAA2B;AAClC,WAAO,YAAY;AAAA,EACvB;AAAA,EAEA,MAAM,OACF,OACA,SACuB;AACvB,QAAI;AACA,UAAI,aAAa;AAEjB,UAAI,WAAW,QAAQ,UAAU,QAAW;AACxC,qBAAa,OAAO,QAAQ,UAAU,WAChC,SAAS,QAAQ,OAAO,EAAE,IAC1B,QAAQ;AAAA,MAClB;AAEA,YAAM,gBAAgB;AAAA,QAClB,gBAAe,mCAAS,kBAAiB;AAAA,QACzC;AAAA,QACA,QAAO,mCAAS,SAAQ;AAAA,QACxB,cAAa,mCAAS,gBAAe;AAAA,QACrC,gBAAe,mCAAS,kBAAiB;AAAA,QACzC,OAAM,mCAAS,SAAQ;AAAA,MAC3B;AAEA,YAAM,WAAW,MAAM,KAAK,aAAa,OAAO,OAAO,aAAa;AAEpE,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,YAAM;AAAA,IACV;AAAA,EACJ;AACJ;;;ACtDO,IAAM,uBAAuB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACPpC,SAAS,wBAA4C;AAG9C,IAAM,gCAAgC;AACtC,IAAM,yBAAyB;AAK/B,SAAS,yBACZ,KACA,eAA8B,wBAChC;AACE,QAAM,WAAW,iBAAiB,YAAY;AAC9C,SAAO,SAAS,OAAO,GAAG,EAAE;AAChC;AAKO,SAAS,UACZ,MACA,YAAoB,+BACd;AACN,MAAI,yBAAyB,IAAI,KAAK,WAAW;AAC7C,WAAO,KAAK,MAAM,GAAG,SAAS;AAAA,EAClC;AACA,SAAO;AACX;AAKO,SAAS,oBAAoB,QAAsC;AACtE,MAAI,OAAO,WAAW,YAAY,WAAW,MAAM;AAC/C,WAAO;AAAA,EACX;AAGA,MAAI,WAAW,QAAQ;AAEnB,QAAI,OAAO,OAAO,UAAU,UAAU;AAClC,YAAM,cAAc,SAAS,OAAO,OAAO,EAAE;AAC7C,UAAI,MAAM,WAAW,KAAK,cAAc,GAAG;AACvC,eAAO;AAAA,MACX;AAEA,aAAO,QAAQ;AAAA,IACnB,WAAW,OAAO,OAAO,UAAU,YAAY,OAAO,QAAQ,KAAK,CAAC,OAAO,UAAU,OAAO,KAAK,GAAG;AAChG,aAAO;AAAA,IACX;AAAA,EACJ;AAGA,MAAI,UAAU,QAAQ;AAClB,QAAI,OAAO,OAAO,SAAS,YAAa,OAAO,SAAS,UAAU,OAAO,SAAS,WAAY;AAC1F,aAAO;AAAA,IACX;AAAA,EACJ;AAEA,SAAO;AACX;;;ACzDO,IAAM,oBAAoB;AAAA,EAC7B;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS,EAAE,MAAM,yCAAyC;AAAA,IAC9D;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS,EAAE,MAAM,wCAAwC;AAAA,IAC7D;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AACJ;;;AJrFO,IAAM,YAAoB;AAAA,EAC7B,MAAM;AAAA,EACN,SAAS;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACJ;AAAA,EACA,wBAAwB;AAAA,EACxB,aAAa;AAAA,EACb,UAAU,OAAO,YAA2B;AACxC,WAAO,CAAC,CAAC,QAAQ,WAAW,gBAAgB;AAAA,EAChD;AAAA,EACA,SAAS,OACL,SACA,SACA,OACA,UACA,aACC;AA7CT;AA8CQ,YAAS,MAAM,QAAQ,aAAa,OAAO;AAC3C,UAAM,SAAS,QAAQ;AACvB,gBAAY,IAAI,0BAA0B,QAAQ,QAAQ,IAAI;AAE9D,QAAI;AACA,YAAM,qBAAqB,MAAM,sBAAsB,CAAC;AAGxD,YAAM,0BAA0B,mBAAmB,UAAU,OACzD,EAAE,WAAW,EAAE,QAAQ,SAAS,QAAQ,QAAQ,IAAI;AAIxD,UAAI,2BAA2B;AAC/B,UAAI,2BAA2B,KAAK,0BAA0B,mBAAmB,SAAS,GAAG;AAEzF,iBAAS,IAAI,0BAA0B,GAAG,IAAI,mBAAmB,QAAQ,KAAK;AAC1E,gBAAM,IAAI,mBAAmB,CAAC;AAC9B,cAAI,EAAE,YAAY,QAAQ,SAAS;AAC/B,uCAA2B;AAC3B;AAAA,UACJ;AAAA,QACJ;AAAA,MACJ;AAGA,YAAM,mBAAmB,4BAA4B,mBAChD,OAAO,OAAK,EAAE,YAAY,QAAQ,OAAO,EACzC,IAAI;AAET,YAAM,yBAAuB,0DAAkB,YAAlB,mBAA2B,SAAQ,QAAQ,QAAQ;AAEhF,YAAM,sBAAsB,eAAe;AAAA,QACvC,OAAO;AAAA,UACH,GAAG;AAAA,UACH,SAAS;AAAA,QACb;AAAA,QACA,UAAU;AAAA,MACd,CAAC;AAED,YAAM,eAAe,MAAM,yBAAyB;AAAA,QAChD;AAAA,QACA,SAAS;AAAA,QACT,YAAY,WAAW;AAAA,MAC3B,CAAC;AAGD,YAAM,gBAAgB,oBAAoB,YAAY;AACtD,UAAI,CAAC,eAAe;AAChB,oBAAY,KAAK,2CAA2C;AAAA,MAChE;AAGA,YAAM,kBAAkB,aAAa;AACrC,kBAAY,IAAI,oCAAoC,eAAe;AAInE,YAAM,mBAAmB,IAAI,iBAAiB;AAC9C,YAAM,iBAAiB,WAAW,OAAO;AAGzC,YAAM,gBAAgB,gBAAgB;AAAA,QAClC,OAAO,OAAO,aAAa,UAAU,WAC/B,SAAS,aAAa,OAAO,EAAE,IAC/B,aAAa;AAAA,QACnB,MAAM,aAAa;AAAA,MACvB,IAAI;AAEJ,YAAM,iBAAiB,MAAM,iBAAiB;AAAA,QAC1C;AAAA,QACA;AAAA,MACJ;AAEA,UAAI,kBAAkB,eAAe,QAAQ,QAAQ;AAEjD,cAAM,SAAQ,+CAAe,UAAS;AAGtC,cAAM,iBAAiB,eAAe,QAAQ,MAAM,GAAG,KAAK;AAE5D,cAAM,eAAe,eAAe,SAC9B,GAAG,eAAe,MAAM,GACpB,MAAM,QAAQ,cAAc,KAC5B,eAAe,SAAS,IAClB;AAAA;AAAA;AAAA,EAA6D,eACxD;AAAA,UACG,CAAC,QAAsB,UACnB,GAAG,QAAQ,CAAC,MAAM,OAAO,KAAK,KAAK,OAAO,GAAG;AAAA,QACrD,EACC,KAAK,IAAI,CAAC,KACf,EACV,KACA;AAEN,iBAAS;AAAA,UACL,MAAM,UAAU,cAAc,6BAA6B;AAAA,QAC/D,CAAC;AAAA,MACL,OAAO;AACH,oBAAY,MAAM,mCAAmC;AAAA,MACzD;AAAA,IACJ,SAAS,OAAO;AACZ,kBAAY,MAAM,gCAAgC,KAAK;AAAA,IAC3D;AAAA,EACJ;AAAA,EACA,UAAU;AACd;;;AKxJA;AAAA,EAMI,eAAAA;AAAA,EACA,kBAAAC;AAAA,EACA,4BAAAC;AAAA,EACA;AAAA,EACA,cAAAC;AAAA,OACG;;;ACXP,SAAS,oBAAAC,yBAA4C;AAkC9C,SAAS,aAAa,MAA0B;AACnD,MAAI,CAAC,QAAQ,CAAC,MAAM,QAAQ,IAAI,GAAG;AAC/B,WAAO,CAAC;AAAA,EACZ;AAEA,SAAO,KAAK,OAAO,SAAO;AACtB,QAAI;AAEA,UAAI,IAAI,GAAG;AACX,aAAO;AAAA,IACX,SAAS,GAAG;AACR,aAAO;AAAA,IACX;AAAA,EACJ,CAAC;AACL;AAoHO,SAAS,uBAAuB,QAAkD;AACrF,QAAM,mBAAwD;AAAA,IAC1D,MAAM,CAAC;AAAA,EACX;AAGA,MAAI,OAAO,OAAO,kBAAkB,UAAU;AAC1C,UAAM,aAAa,OAAO,OAAO,aAAa,EAAE,YAAY;AAC5D,qBAAiB,gBAAgB,eAAe;AAAA,EACpD,WAAW,OAAO,OAAO,kBAAkB,WAAW;AAClD,qBAAiB,gBAAgB,OAAO;AAAA,EAC5C,OAAO;AACH,qBAAiB,gBAAgB;AAAA,EACrC;AAGA,MAAI,OAAO,OAAO,iBAAiB,UAAU;AACzC,UAAM,aAAa,OAAO,aAAa,YAAY;AACnD,QAAI,eAAe,WAAW,eAAe,YAAY;AACrD,uBAAiB,eAAe;AAAA,IACpC,OAAO;AACH,uBAAiB,eAAe;AAAA,IACpC;AAAA,EACJ,OAAO;AACH,qBAAiB,eAAe;AAAA,EACpC;AAGA,MAAI,MAAM,QAAQ,OAAO,IAAI,GAAG;AAC5B,qBAAiB,OAAO,OAAO;AAAA,EACnC;AAEA,SAAO;AACX;;;AC9LO,IAAM,wBAAwB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACF9B,IAAM,0BAA0B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACDhC,IAAM,qBAAqB;AAAA,EAC9B;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AACJ;;;AC7HA;AAAA,EACI,WAAAC;AAAA,EAEA,eAAAC;AAAA,OACG;AACP,SAAS,UAAAC,eAAc;AAUhB,IAAM,oBAAN,MAAM,2BAA0BF,SAAsC;AAAA,EAClE;AAAA,EAEP,MAAM,WAAW,UAAwC;AACrD,UAAM,SAAS,SAAS,WAAW,gBAAgB;AACnD,QAAI,CAAC,QAAQ;AACT,YAAM,IAAI,MAAM,2BAA2B;AAAA,IAC/C;AACA,SAAK,eAAeE,QAAO,EAAE,OAAO,CAAC;AAAA,EACzC;AAAA,EAEA,cAAkC;AAC9B,WAAO,mBAAkB,YAAY;AAAA,EACzC;AAAA,EAEA,WAAW,cAA2B;AAClC,WAAOD,aAAY;AAAA,EACvB;AAAA,EAEA,MAAM,QACF,MACA,SACwB;AACxB,QAAI;AACA,YAAM,gBAAgB;AAAA,QAClB,gBAAe,mCAAS,kBAAiB;AAAA,MAC7C;AAEA,YAAM,iBAAiB,MAAM,KAAK,aAAa,QAAQ,IAAI;AAE3D,YAAM,cAAc;AAEpB,YAAM,qBAAgD,YAAY,WAAW,CAAC,GAAG,IAAI,CAAC,YAAiB;AAAA,QACnG,KAAK,OAAO;AAAA,QACZ,aAAa,OAAO,cAAc,OAAO,WAAW;AAAA,QACpD,QAAQ,OAAO;AAAA,MACnB,EAAE;AAEF,YAAM,iBAAwC,YAAY,iBAAiB,CAAC,GAAG,IAAI,CAAC,YAAiB;AAAA,QACjG,KAAK,OAAO;AAAA,QACZ,OAAO,OAAO,SAAS;AAAA,MAC3B,EAAE;AAEF,YAAM,WAA4B;AAAA,QAC9B,SAAS;AAAA,QACT,gBAAgB;AAAA,QAChB,eAAe,YAAY,gBAAgB;AAAA,MAC/C;AAEA,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,YAAM;AAAA,IACV;AAAA,EACJ;AACJ;;;ALlDO,IAAM,aAAqB;AAAA,EAC9B,MAAM;AAAA,EACN,SAAS;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACJ;AAAA,EACA,wBAAwB;AAAA,EACxB,aAAa;AAAA,EACb,UAAU,OAAO,YAA2B;AACxC,WAAO,CAAC,CAAC,QAAQ,WAAW,gBAAgB;AAAA,EAChD;AAAA,EACA,SAAS,OACL,SACA,SACA,OACA,UACA,aACC;AACD,YAAS,MAAM,QAAQ,aAAa,OAAO;AAC3C,QAAI;AACJ,QAAI,wBAAwB;AAC5B,QAAI,SAAS;AAEb,QAAI;AAEA,YAAM,uBAAuBE,gBAAe;AAAA,QACxC,OAAO;AAAA,UACH,GAAG;AAAA,UACH,SAAS,QAAQ,QAAQ;AAAA,QAC7B;AAAA,QACA,UAAU;AAAA,MACd,CAAC;AAED,YAAM,gBAAgB,MAAMC,0BAAyB;AAAA,QACjD;AAAA,QACA,SAAS;AAAA,QACT,YAAYC,YAAW;AAAA,MAC3B,CAAC;AAGD,YAAM,mBAAmB,uBAAuB,iBAAiB,CAAC,CAAC;AAGnE,YAAM,YAAY,aAAa,iBAAiB,IAAI;AAEpD,UAAI,UAAU,WAAW,GAAG;AAExB,gCAAwB;AACxB,iBAAS;AAAA,MACb,OAAO;AACH,cAAM,oBAAoB,IAAI,kBAAkB;AAChD,cAAM,kBAAkB,WAAW,OAAO;AAE1C,cAAM,iBAAiB;AAAA,UACnB,eAAe,iBAAiB,kBAAkB,SAAY,iBAAiB,gBAAgB;AAAA,UAC/F,cAAe,iBAAiB,gBAAyC;AAAA,QAC7E;AAEA,YAAI;AACA,4BAAkB,MAAM,kBAAkB,QAAQ,WAAW,cAAc;AAE3E,cAAI,mBAAmB,gBAAgB,QAAQ,QAAQ;AAEnD,4BAAgB,QAAQ,QAAQ,CAAC,QAAiC,UAAkB;AAChF,uCAAyB,OAAO,QAAQ,CAAC,KAAK,OAAO,GAAG;AAAA;AACxD,uCAAyB,YAAY,OAAO,WAAW;AAAA;AAGvD,kBAAI,OAAO,UAAU,OAAO,OAAO,SAAS,GAAG;AAC3C,yCAAyB,WAAW,OAAO,OAAO,MAAM;AAAA;AAAA,cAC5D;AAEA,uCAAyB;AAAA,YAC7B,CAAC;AAGD,gBAAI,gBAAgB,kBAAkB,gBAAgB,eAAe,SAAS,GAAG;AAC7E,uCAAyB;AAEzB,8BAAgB,eAAe,QAAQ,CAAC,QAA6B,UAAkB;AACnF,yCAAyB,OAAO,QAAQ,CAAC,KAAK,OAAO,GAAG,aAAa,OAAO,KAAK;AAAA;AAAA,cACrF,CAAC;AAED,uCAAyB;AAAA,YAC7B;AAEA,qBAAS;AAAA,UACb,OAAO;AACH,oCAAwB;AACxB,qBAAS;AAAA,UACb;AAAA,QACJ,SAAS,OAAO;AACZ,UAAAC,aAAY,MAAM,iCAAiC,KAAK;AACxD,kCAAwB,iDAAiD,MAAM,WAAW,eAAe;AAAA;AACzG,mBAAS;AAAA,QACb;AAAA,MACJ;AAAA,IACJ,SAAS,OAAO;AACZ,MAAAA,aAAY,MAAM,iCAAiC,KAAK;AACxD,8BAAwB,oDAAoD,MAAM,WAAW,eAAe;AAC5G,eAAS;AAAA,IACb;AAGA,UAAM,kBAAkBH,gBAAe;AAAA,MACnC,OAAO;AAAA,QACH,GAAG;AAAA,QACH,mBAAmB;AAAA,QACnB,cAAc,kBAAkB,gBAAgB,gBAAgB;AAAA,QAChE;AAAA,QACA,iBAAiB,QAAQ,QAAQ;AAAA,MACrC;AAAA,MACA,UAAU;AAAA,IACd,CAAC;AAED,UAAM,oBAAoB,MAAM,aAAa;AAAA,MACzC;AAAA,MACA,SAAS;AAAA,MACT,YAAYE,YAAW;AAAA,IAC3B,CAAC;AAED,aAAS;AAAA,MACL,MAAM;AAAA,IACV,CAAC;AAAA,EACL;AAAA,EACA,UAAU;AACd;;;AMzJO,IAAM,kBAAkB;AAAA,EAC3B,MAAM;AAAA,EACN,aAAa;AAAA,EACb,SAAS,CAAC,WAAW,UAAU;AACnC;","names":["elizaLogger","composeContext","generateObjectDeprecated","ModelClass","encodingForModel","Service","ServiceType","tavily","composeContext","generateObjectDeprecated","ModelClass","elizaLogger"]}